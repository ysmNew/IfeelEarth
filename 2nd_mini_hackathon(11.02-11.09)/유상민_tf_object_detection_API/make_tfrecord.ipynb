{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"make_tfrecord.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TfWnwwCI3sef"},"source":["이 문제를 해결하는 방법에는 두 가지가 있습니다.\n","\n","- 공개 레이블이 지정된 데이터 세트 사용\n","- 라벨이 지정된 맞춤 데이터 세트 만들기\n","\n","이 자습서에서는 처음부터 자체 데이터 세트를 생성합니다.\n","\n","먼저 데이터 세트의 이미지를 수집합니다. 이 단계는 이미 완료되었다고 가정합니다.\n","\n","이제 이미지에 레이블을 지정해야합니다. 많은 인기있는 라벨링 도구가 있으며 LabelIMG를 사용할 것입니다.\n","\n","LabelIMG를 설치하려면 다음 코드를 실행하십시오 (Colab은 GUI 응용 프로그램을 지원하지 않으므로 로컬 터미널에서 수행하십시오).\n","\n","```\n","pip install labelImg\n","```\n","```\n","labelImg imagesdir\n","```\n","![](https://ichi.pro/assets/images/max/724/1*6iL6pI9bVRV9qa8RvpzkEA.png)\n","\n","예를 들어 자동차 및 자전거와 같은 두 가지 클래스를 사용하여 다음과 같이 메모장에 레이블 맵 (label_map.pbtxt)을 만듭니다.\n","\n","```\n","item {\n","    id: 1\n","    name: 'car'\n","}\n","\n","item {\n","    id: 2\n","    name: 'bike'\n","}\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3vj0nBJhBImB"},"source":["# json 병합\n","\n","https://dacon.io/competitions/official/235644/codeshare/1705?page=1&dtype=recent\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-Zex6UHBF5g","executionInfo":{"status":"ok","timestamp":1636236862645,"user_tz":-540,"elapsed":332,"user":{"displayName":"유상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09996795806665098241"}},"outputId":"a6ca6167-0cc3-4792-883a-4eed84d9841c"},"source":["import os\n","label_path = '/content/drive/Shareddrives/OD/data_real/train_etc/labels/'\n","files = os.listdir(label_path)\n","print('json 파일 총 개수 :', len(files))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["json 파일 총 개수 : 1748\n"]}]},{"cell_type":"code","metadata":{"id":"Uk9UWBurJ0Dx"},"source":["import json\n","\n","all_json = None\n","\n","for file in files :\n","    json_data = json.load(open(label_path + file))\n","\n","    if all_json == None: \n","        all_json = json_data\n","    else: \n","        all_json['features'].extend(json_data['features'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4PGs2RrJ3_X"},"source":["with open('/content/drive/Shareddrives/OD/data_real/train_etc/labels/labels.json', 'w') as outfile:\n","    json.dump(all_json, outfile, indent='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l0NfxOSJf-pb"},"source":["label.json 파일을 이미지 폴더로 이동"]},{"cell_type":"markdown","metadata":{"id":"iyqH3wbaBE47"},"source":["다음을 수행 할 수 있습니다.\n","\n","- 직접 TFRecord 만들기\n","- Roboflow에 주석을 업로드하고 TFRecord 형식으로 데이터 세트를 가져옵니다.\n","\n","참고로 여기에 TFRecord를 수동으로 생성하는 샘플 .py 스크립트가 있습니다.\n","\n","```python\n","import pandas as pd\n","import numpy as np\n","import csv\n","import re\n","import cv2 \n","import os\n","import glob\n","import xml.etree.ElementTree as ET\n","\n","import io\n","import tensorflow as tf\n","from collections import namedtuple, OrderedDict\n","\n","import shutil\n","import urllib.request\n","import tarfile\n","import argparse\n","\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n","import tensorflow.compat.v1 as tf\n","from PIL import Image\n","from object_detection.utils import dataset_util, label_map_util\n","from collections import namedtuple\n","xml_dir = 'images/test'\n","image_dir = 'images/test'\n","\n","label_map = label_map_util.load_labelmap('annotations/label_map.pbtxt')\n","label_map_dict = label_map_util.get_label_map_dict(label_map)\n","\n","output_path = 'annotations/test.record'\n","\n","def xml_to_csv(path):\n","    \"\"\"Iterates through all .xml files (generated by labelImg) in a given directory and combines\n","    them in a single Pandas dataframe.\n","\n","    Parameters:\n","    ----------\n","    path : str\n","        The path containing the .xml files\n","    Returns\n","    -------\n","    Pandas DataFrame\n","        The produced dataframe\n","    \"\"\"\n","\n","    xml_list = []\n","    for xml_file in glob.glob(path + '/*.xml'):\n","        tree = ET.parse(xml_file)\n","        root = tree.getroot()\n","        for member in root.findall('object'):\n","            value = (root.find('filename').text,\n","                     int(root.find('size')[0].text),\n","                     int(root.find('size')[1].text),\n","                     member[0].text,\n","                     int(member[4][0].text),\n","                     int(member[4][1].text),\n","                     int(member[4][2].text),\n","                     int(member[4][3].text)\n","                     )\n","            xml_list.append(value)\n","    column_name = ['filename', 'width', 'height',\n","                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","    xml_df = pd.DataFrame(xml_list, columns=column_name)\n","    return xml_df\n","\n","\n","def class_text_to_int(row_label):\n","    return label_map_dict[row_label]\n","\n","\n","def split(df, group):\n","    data = namedtuple('data', ['filename', 'object'])\n","    gb = df.groupby(group)\n","    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","\n","def create_tf_example(group, path):\n","    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","        encoded_jpg = fid.read()\n","    encoded_jpg_io = io.BytesIO(encoded_jpg)\n","    image = Image.open(encoded_jpg_io)\n","    width, height = image.size\n","\n","    filename = group.filename.encode('utf8')\n","    image_format = b'jpg'\n","    xmins = []\n","    xmaxs = []\n","    ymins = []\n","    ymaxs = []\n","    classes_text = []\n","    classes = []\n","\n","    for index, row in group.object.iterrows():\n","        xmins.append(row['xmin'] / width)\n","        xmaxs.append(row['xmax'] / width)\n","        ymins.append(row['ymin'] / height)\n","        ymaxs.append(row['ymax'] / height)\n","        classes_text.append(row['class'].encode('utf8'))\n","        classes.append(class_text_to_int(row['class']))\n","\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","        'image/height': dataset_util.int64_feature(height),\n","        'image/width': dataset_util.int64_feature(width),\n","        'image/filename': dataset_util.bytes_feature(filename),\n","        'image/source_id': dataset_util.bytes_feature(filename),\n","        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","        'image/format': dataset_util.bytes_feature(image_format),\n","        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","        'image/object/class/label': dataset_util.int64_list_feature(classes),\n","    }))\n","    return tf_example\n","\n","csv_path = None\n","def main(_):\n","\n","    writer = tf.python_io.TFRecordWriter(output_path)\n","    path = os.path.join(image_dir)\n","    examples = xml_to_csv(xml_dir)\n","    grouped = split(examples, 'filename')\n","    for group in grouped:\n","        tf_example = create_tf_example(group, path)\n","        writer.write(tf_example.SerializeToString())\n","    writer.close()\n","    print('Successfully created the TFRecord file: {}'.format(output_path))\n","    if csv_path is not None:\n","        examples.to_csv(csv_path, index=None)\n","        print('Successfully created the CSV file: {}'.format(csv_path))\n","\n","if __name__ == '__main__':\n","    tf.app.run()\n","```\n","\n","train 및 test 이미지에 위의 코드를 사용하여 각각 train.tfrecord 및 test.tfrecord를 변경하여\n","\n","```\n","xml_dir = ‘images/test’\n","image_dir = ‘images/test’\n","output_path = 'annotations/test.record'\n","```"]},{"cell_type":"markdown","metadata":{"id":"ya4zi--PgYrO"},"source":["# tfrecord 생성\n","\n","https://github.com/SIAnalytics/simplified_rbox_cnn/blob/master/create_dataset.py\n","\n","필요한 부분 수정한 **create_dataset.py**"]},{"cell_type":"code","metadata":{"id":"3rsI_hqx4Fog"},"source":["!ln -s /content/drive/Shareddrives/OD/create_dataset.py ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZa1KJBs6T2r","executionInfo":{"status":"ok","timestamp":1636242674063,"user_tz":-540,"elapsed":271,"user":{"displayName":"유상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09996795806665098241"}},"outputId":"2163290c-d43e-4a3f-c515-6f97a3c949b7"},"source":["%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/workspace\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZY3abvXI6iFb","executionInfo":{"status":"ok","timestamp":1636244258825,"user_tz":-540,"elapsed":1349669,"user":{"displayName":"유상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09996795806665098241"}},"outputId":"67270812-9d7d-40c5-fb01-4d2df66c5053"},"source":["!python create_dataset.py --src_dir=/content/drive/Shareddrives/OD/data_real/train/ \\\n","                                    --dst_path=./train.tfrecord \\\n","                                    --is_include_only_pos"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 1748/1748 [22:01<00:00,  1.32it/s]\n","N of TFRecords: 6506\n"]}]},{"cell_type":"markdown","metadata":{"id":"-wYXQOt3ixRF"},"source":["이하 val 에 대해 반복"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QJcaOIHzc-Pv","executionInfo":{"status":"ok","timestamp":1636244287721,"user_tz":-540,"elapsed":2696,"user":{"displayName":"유상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09996795806665098241"}},"outputId":"a0b80e33-be49-463c-e6a2-837172f2b0a4"},"source":["import os\n","label_path = '/content/drive/Shareddrives/OD/data_real/val_etc/labels/'\n","files = os.listdir(label_path)\n","print('json 파일 총 개수 :', len(files))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["json 파일 총 개수 : 220\n"]}]},{"cell_type":"code","metadata":{"id":"ZcbcuEp7dMOU"},"source":["import json\n","\n","all_json = None\n","\n","for file in files :\n","    json_data = json.load(open(label_path + file))\n","\n","    if all_json == None: \n","        all_json = json_data\n","    else: \n","        all_json['features'].extend(json_data['features'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Exk0jZ6hdPnc"},"source":["with open('/content/drive/Shareddrives/OD/data_real/val_etc/labels/labels.json', 'w') as outfile:\n","    json.dump(all_json, outfile, indent='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1h_09duJdT34"},"source":["! cd /content/drive/Shareddrives/OD/data_real/val_etc/labels && mv labels.json /content/drive/Shareddrives/OD/data_real/val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reMkI_4iO0BW","executionInfo":{"status":"ok","timestamp":1636246442741,"user_tz":-540,"elapsed":146978,"user":{"displayName":"유상민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09996795806665098241"}},"outputId":"b77fe802-ec52-4fbe-dead-c19df6f355c1"},"source":["!python create_dataset.py --src_dir=/content/drive/Shareddrives/OD/data_real/val/ \\\n","                                    --dst_path=./val.tfrecord \\\n","                                    --is_include_only_pos"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 220/220 [02:18<00:00,  1.59it/s]\n","N of TFRecords: 822\n"]}]},{"cell_type":"markdown","metadata":{"id":"-tqo0Ykff7Na"},"source":["# 사전 훈련 된 모델 다운로드\n","Tensorflow Model Zoo 에서 다운로드 할 준비가 된 많은 모델이 있습니다 .\n","\n","일부 모델은 물체 감지 용이 아니므로 사용할 모델을 선택하는 데주의하십시오. 이 자습서에서는 다음 모델을 사용합니다.\n","\n","SSD MobileNet V2 FPNLite 320x320 .\n","\n","Colab Notebook에 다운로드하고 다음을 실행하여 압축을 풉니 다.\n","\n","```\n","%cd pre-trained-models\n","!curl \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\" --output \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n","model_name = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n","model_file = model_name + '.tar.gz'\n","tar = tarfile.open(model_file)\n","tar.extractall()\n","tar.close()\n","os.remove(model_file)\n","```\n","\n","```\n","workspace/\n","├─ models/\n","│  ├─ community/\n","│  ├─ official/\n","│  ├─ orbit/\n","│  ├─ research/\n","│  ├─ my_mobilenet/\n","│  └─ ...\n","├─ annotations/\n","│  ├─ train/\n","│  └─ test/\n","├─ pre-trained-model/\n","├─ exported-models/\n","```\n","\n","TF Object Detection API에서 모델 학습 및 평가에 필요한 모든 설정 및 필수 정보는 pipeline.config 파일에 있습니다.\n","\n","살펴 보겠습니다.\n","\n","우리가 변경해야 할 가장 중요한 것은\n","```\n","batch_size: 128\n","fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n","num_steps: 50000\n","num_classes: 2\n","fine_tune_checkpoint_type: \"classification\"\n","train_input_reader {   \n","  label_map_path: \"PATH_TO_BE_CONFIGURED\"   \n","  tf_record_input_reader {     \n","    input_path: \"PATH_TO_BE_CONFIGURED\"   \n","  } \n","} \n","eval_input_reader {   \n","  label_map_path: \"PATH_TO_BE_CONFIGURED\"   \n","  shuffle: false   \n","  num_epochs: 1   \n","  tf_record_input_reader {     \n","    input_path: \"PATH_TO_BE_CONFIGURED\"   \n","  }\n","}\n","```\n","\n","실제 변경한 내용\n","\n","`modified_pipeline.config` 로 저장\n","\n","```\n","# For Fresh Training\n","fine_tune_checkpoint: \"pre-trained-model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n","# For Contuining the Training\n","fine_tune_checkpoint: \"exported_models/your_latest_batch/checkpoint/ckpt-0\"\n","batch_size = 8 # Increase/Decrease this value depending on how fast your train job runs and the availability of the Compute Resources.\n","num_steps: 25000 # 25000 is a good number of steps to get a good loss.\n","fine_tune_checkpoint_type: \"detection\" # Set this to detection\n","train_input_reader {   \n","  label_map_path: \"annotations/label_map.pbtxt\"   # Set to location of label map\n","  tf_record_input_reader {     \n","    input_path: \"annotations/train.tfrecord\"   # Set to location of train TFRecord file\n","  } \n","}\n","# Similarly do the same for the eval input reader\n","eval_input_reader {   \n","  label_map_path: \"annotations/label_map.pbtxt\"   \n","  shuffle: false   \n","  num_epochs: 1   \n","  tf_record_input_reader {     \n","    input_path: \"annotations/test.tfrecord\"   \n","  }\n","}\n","```\n","\n","StackOverflow 에 대한 좋은 제안 은 다음과 같습니다.\n","\n","**최대 배치 크기 = 사용 가능한 GPU 메모리 바이트 / 4 / (텐서 크기 + 학습 가능한 매개 변수)**\n","\n","**fine_tune_checkpoint** 는 마지막으로 훈련 된 체크 포인트입니다 (체크 포인트는 Tensorflow 에서 모델을 저장하는 방법입니다).\n","\n","처음으로 훈련을 시작하는 경우 이를 사전 훈련 된 모델로 설정하십시오.\n","\n","이전에 훈련 된 체크 포인트에서 훈련을 계속하려면 해당 체크 포인트 경로로 설정하십시오. (이것은 처음부터 시작하는 대신 기능과 손실을 기반으로 교육을 계속할 것입니다)."]},{"cell_type":"code","metadata":{"id":"IuBpAOodmzHd"},"source":[""],"execution_count":null,"outputs":[]}]}